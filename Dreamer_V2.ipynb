{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNamzjZdUM/sdwVA3E5M+MA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seki-shu/Group15_Multimodal/blob/Dreamer-V2/Dreamer_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 準備"
      ],
      "metadata": {
        "id": "TfdWO2_f_ZwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## libraryのimport"
      ],
      "metadata": {
        "id": "0GIGUoGO-vBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.distributions as td\n",
        "from torch.distributions import Normal, Categorical, OneHotCategorical, OneHotCategoricalStraightThrough, Bernoulli\n",
        "from torch.distributions import kl_divergence"
      ],
      "metadata": {
        "id": "6IyU5N79-2YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## deviceの確認"
      ],
      "metadata": {
        "id": "eKy-1uif_TRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.deviceを定義．この変数は後々モデルやデータをGPUに転送する時にも使います\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "ogLmXvsB_gPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデルの実装\n"
      ],
      "metadata": {
        "id": "OpdMlxUpvtI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RSSM"
      ],
      "metadata": {
        "id": "Ucy9NSR8vxgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RSSM(nn.Module):\n",
        "    \"\"\"\n",
        "    RSSMのクラス.\n",
        "\n",
        "    Methods:\n",
        "    --------\n",
        "        recurrent: 決定的状態hをrnnで得る.\n",
        "        get_prior: 確率的状態zの事前分布を得る.\n",
        "        get_posterior: 確率的状態zの事後分布を得る.\n",
        "    \"\"\"\n",
        "    def __init__(self, mlp_hidden_dim: int, h_dim: int, z_dim: int, a_dim: int, n_classes: int, embedding_dim: int):\n",
        "        \"\"\"\n",
        "        コンストラクタ.\n",
        "\n",
        "        Params:\n",
        "        --------\n",
        "            mlp_hidden_dim : int\n",
        "               mlpに通した後の次元数.\n",
        "            h_dim : int\n",
        "               決定的状態hの次元数.\n",
        "            z_dim : int\n",
        "               確率的状態zの次元数.\n",
        "            a_dim : int\n",
        "               行動の次元数.\n",
        "            n_classes : int\n",
        "               確率的状態zのカテゴリ数.\n",
        "            embedding_dim : int\n",
        "               観測画像の埋め込み次元数.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.h_dim = h_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.a_dim = a_dim\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # Recurrent model\n",
        "        # h_t = f(h_t-1, z_t-1, a_t-1)\n",
        "        self.z_a_hidden = nn.Linear(z_dim * n_classes + a_dim, mlp_hidden_dim)\n",
        "        self.rnn = nn.GRUCell(mlp_hidden_dim, h_dim)\n",
        "\n",
        "        # Prior prediction\n",
        "        # z_t+1_hat = f(h_t+1)\n",
        "        self.prior_hidden = nn.Linear(h_dim, mlp_hidden_dim)\n",
        "        self.prior_logits = nn.Linear(mlp_hidden_dim, z_dim * n_classes)\n",
        "\n",
        "        # Posterior\n",
        "        # z_t+1 = f(h_t+1, o_t+1)\n",
        "        self.posterior_hidden = nn.Linear(h_dim + embedding_dim, mlp_hidden_dim)\n",
        "        self.posterior_logits = nn.Linear(mlp_hidden_dim, z_dim * n_classes)\n",
        "\n",
        "    def recurrent(self, h_prev: torch.Tensor, z_prev: torch.Tensor, a_prev: torch.Tensor, rnn_hidden: torch.Tensor):\n",
        "        \"\"\"\n",
        "        決定的状態の状態遷移を求めるメソッド. RNNとしてGRUを使用する.\n",
        "        h_t+1 = f(h_t, z_t, a_t)\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h_prev : torch.Tensor (batch size, h_dim)\n",
        "                現在時刻の決定的状態h_t\n",
        "            z_prev : torch.Tensor (batch size, z_dim)\n",
        "                現在時刻の確率的状態z_t\n",
        "            a_prev : torch.Tensor (batch size, a_dim)\n",
        "                現在時刻のアクションa_t\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                次時刻の決定的状態h_t+1\n",
        "        \"\"\"\n",
        "        mlp_hidden = F.elu(self.z_a_hidden(torch.cat([z_prev, a_prev], dim=1)))\n",
        "        h = self.rnn(mlp_hidden, rnn_hidden)\n",
        "        return h\n",
        "\n",
        "    def get_prior(self,h: torch.Tensor, detach = False):\n",
        "        \"\"\"\n",
        "        確率的状態zの事前分布を求めるメソッド.\n",
        "        z_t+1_hat ~ p(h_t+1)\n",
        "\n",
        "        Params:\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                次時刻の決定的状態h_t+1.\n",
        "            detach : bool\n",
        "                Trueの場合、detachする.\n",
        "\n",
        "        ---------\n",
        "        Returns:\n",
        "            prior : torch.distributions.Distribution\n",
        "                事前分布を求めるためのカテゴリカル分布.\n",
        "            detached_prior : torch.distributions.Independent\n",
        "                detachされた事前分布を求めるためのカテゴリカル分布.\n",
        "        \"\"\"\n",
        "        mlp_hidden = F.elu(self.prior_hidden(h))\n",
        "        logits = self.prior_logits(mlp_hidden) # (B, z_dim * n_classes,)\n",
        "        logits = logits.reshape(logits.shape[0], self.z_dim, self.n_classes) # (B, z_dim, n_classes)\n",
        "\n",
        "        prior = td.Independent(OneHotCategoricalStraightThrough(logits=logits), 1)\n",
        "        if detach:\n",
        "            detached_prior = td.Independent(OneHotCategoricalStraightThrough(logits=logits.detach()), 1)\n",
        "            return prior, detached_prior\n",
        "        return prior\n",
        "\n",
        "    def get_posterior(self, h: torch.Tensor, embedded_obs: torch.Tensor, detach = False):\n",
        "        \"\"\"\n",
        "        確率的状態zの事後分布を求めるメソッド.\n",
        "        z_t+1 ~ p(h_t+1, o_t+1)\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                次時刻の決定的状態h_t+1.\n",
        "            embedded_obs : torch.Tensor (batch size, embedding_dim)\n",
        "                次時刻の画像の埋め込み\n",
        "            detach : bool\n",
        "                Trueの場合、detachする.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "            posterior : torch.distributions.Distribution\n",
        "                事後分布を求めるためのカテゴリカル分布.\n",
        "            detached_posterior : torch.distributions.Independent\n",
        "                detachされた事後分布を求めるためのカテゴリカル分布.\n",
        "        \"\"\"\n",
        "        mlp_hidden = F.elu(self.posterior_hidden(torch.cat([h, embedded_obs], dim=1)))\n",
        "        logits = self.posterior_logits(mlp_hidden) # (B, z_dim * n_classes)\n",
        "        logits = logits.reshape(logits.shape[0], self.z_dim, self.n_classes) # (B, z_dim, n_classes)\n",
        "\n",
        "        posterior = td.Independent(OneHotCategoricalStraightThrough(logits=logits), 1)\n",
        "        if detach:\n",
        "            detached_posterior = td.Independent(OneHotCategoricalStraightThrough(logits=logits.detach()), 1)\n",
        "            return posterior, detached_posterior\n",
        "        return posterior"
      ],
      "metadata": {
        "id": "zEnpQhwuv2ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "WMago0IsS1Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    画像(3, 64, 64)をエンコードする.\n",
        "\n",
        "    Methods:\n",
        "    -------\n",
        "        forward: 観測画像を埋め込む.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2)\n",
        "\n",
        "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        順伝播を行うメソッド．観測画像をベクトルに埋め込む．\n",
        "        (3, 64, 64) -> (1024, ) にエンコード\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            obs : torch.Tensor (batch size, 3, 64, 64)\n",
        "                環境から得られた観測画像．\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "            embed : torch.Tensor (batch size, 1024)\n",
        "                観測を1024次元のベクトルに埋め込んだもの．\n",
        "        \"\"\"\n",
        "        embed = F.elu(self.conv1(obs))\n",
        "        embed = F.elu(self.conv2(embed))\n",
        "        embed = F.elu(self.conv3(embed))\n",
        "        embed = F.elu(self.conv4(embed)).reshape(embed.shape[0], -1)\n",
        "        return embed"
      ],
      "metadata": {
        "id": "B5f9vR5_6YrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "3CrHwaS6S3fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    内部状態表現h, zから画像(3, 64, 64)を再構成する.\n",
        "    ただし画像は平均を計算して、その平均で分散１の正規分布から得る.\n",
        "\n",
        "    Methods:\n",
        "        forward: 画像の再構成を行う.\n",
        "    \"\"\"\n",
        "    def __init__(self, h_dim: int, z_dim: int, n_classes: int):\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Params:\n",
        "        --------\n",
        "            h_dim : int\n",
        "                決定的状態hの次元数．\n",
        "            z_dim : int\n",
        "                確率的状態zの次元数．\n",
        "            n_classes : int\n",
        "                確率的状態zのカテゴリ数．\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(h_dim + z_dim * n_classes, 1024)\n",
        "        self.deconv1 = nn.ConvTranspose2d(1024, 128, kernel_size=5, stride=2)\n",
        "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2)\n",
        "        self.deconv3 = nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2)\n",
        "        self.deconv4 = nn.ConvTranspose2d(32, 3, kernel_size=6, stride=2)\n",
        "\n",
        "    def forward(self, h: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        順伝播を行うメソッド．内部状態h, zから画像を再構成する．\n",
        "        mean = f(h_t, z_t)\n",
        "        o_t = N(mean, 1)\n",
        "\n",
        "        Params:\n",
        "        --------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                決定的状態h\n",
        "            z : torch.Tensor (batch size, z_dim * n_classes)\n",
        "                確率的状態z\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "            obs_dist : torch.distributions.Independent\n",
        "                再構成された画像を得るための多変量正規分布．\n",
        "        \"\"\"\n",
        "        x = self.fc(torch.cat([h, z], dim=1))\n",
        "        x = x.reshape(x.shape[0], 1024, 1, 1)\n",
        "        x = F.elu(self.deconv1(x))\n",
        "        x = F.elu(self.deconv2(x))\n",
        "        x = F.elu(self.deconv3(x))\n",
        "        mean = self.deconv4(x)\n",
        "        obs_dist = td.Independent(Normal(mean, 1), 3)\n",
        "        return obs_dist\n"
      ],
      "metadata": {
        "id": "3wS4h5LRS5ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reward Model"
      ],
      "metadata": {
        "id": "NqLaH-bVcdAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RewardModel(nn.Module):\n",
        "    \"\"\"\n",
        "    報酬予測モデル.\n",
        "    ただし報酬は平均を計算して、その平均で分散が1の正規分布から得る.\n",
        "\n",
        "    Methods:\n",
        "    -------\n",
        "        forward: 報酬予測を行う.\n",
        "    \"\"\"\n",
        "    def __init__(self, h_dim: int, z_dim: int, n_classes: int, hidden_dim: int):\n",
        "        \"\"\"\n",
        "        コンストラクタ.\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h_dim : int\n",
        "                決定的状態hの次元数.\n",
        "            z_dim : int\n",
        "                確率的状態zの次元数.\n",
        "            n_classes : int\n",
        "                確率的状態zのカテゴリ数.\n",
        "            hidden_dim : int\n",
        "                MLPを通した後のユニット数.\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(h_dim + z_dim * n_classes, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, h: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        報酬予測を行うメソッド.\n",
        "        mean = f(h_t, z_t)\n",
        "        r_t = N(mean, 1)\n",
        "\n",
        "        Params:\n",
        "        ----------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                決定的状態h\n",
        "            z : torch.Tensor (batch size, z_dim * n_classes)\n",
        "                確率的状態z\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "            reward_dist : torch.distributions.Independent\n",
        "                報酬予測をするための多変量正規分布.\n",
        "        \"\"\"\n",
        "        x = F.elu(self.fc1(torch.cat([h, z], dim=1)))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        mean = self.fc4(x)\n",
        "        reward_dist = td.Independent(Normal(mean, 1), 1)\n",
        "        return reward_dist"
      ],
      "metadata": {
        "id": "kT1UTPlFcfuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discount Model\n"
      ],
      "metadata": {
        "id": "ulP85WUBKp4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiscountModel(nn.Module):\n",
        "    \"\"\"\n",
        "    現在のエピソードが終端かどうかを求めるモデル.\n",
        "\n",
        "    Methods:\n",
        "    --------\n",
        "        forward: 終端かどうか予測を行う.\n",
        "    \"\"\"\n",
        "    def __init__(self, h_dim: int, z_dim: int, n_classes: int, hidden_dim: int):\n",
        "        \"\"\"\n",
        "        コンストラクタ.\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h_dim : int\n",
        "                決定的状態hの次元数.\n",
        "            z_dim : int\n",
        "                確率的状態zの次元数.\n",
        "            n_classes : int\n",
        "                確率的状態zのカテゴリ数.\n",
        "            hidden_dim : int\n",
        "                MLPを通した後のユニット数.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(h_dim + z_dim * n_classes, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, h: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        現在のエピソードが終端かどうか求める.\n",
        "        p = f(h_t, z_t)\n",
        "        gamma_t = Bernoulli(p)\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                決定的状態h\n",
        "            z : torch.Tensor (batch size, z_dim * n_classes)\n",
        "                確率的状態z\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "            discount_dist : torch.distributions.Independent\n",
        "                終端かどうか予測を行うベルヌーイ分布\n",
        "        \"\"\"\n",
        "        x = F.elu(self.fc1(torch.cat([h, z], dim=1)))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        p_logits = self.fc4(x)\n",
        "        discount_dist = td.Independent(Bernoulli(logits=p_logits), 1)\n",
        "        return discount_dist"
      ],
      "metadata": {
        "id": "50mWXQbCKt6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actor"
      ],
      "metadata": {
        "id": "sc3et5bZPUEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Actor(nn.Module):\n",
        "    \"\"\"\n",
        "    最適行動を出力するモデル.\n",
        "    今回はAtariではないので連続な行動を出力する.\n",
        "\n",
        "    Methods:\n",
        "    -------\n",
        "        forward: 最適行動を出力する.\n",
        "    \"\"\"\n",
        "    def __init__(self, action_dim: int, h_dim: int, z_dim: int, n_classes: int, hidden_dim: int):\n",
        "        \"\"\"\n",
        "        コンストラクタ.\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            action_dim : int\n",
        "                行動の次元数.\n",
        "            h_dim : int\n",
        "                決定的状態hの次元数.\n",
        "            z_dim : int\n",
        "                確率的状態zの次元数.\n",
        "            n_classes : int\n",
        "                確率的状態zのカテゴリ数.\n",
        "            hidden_dim : int\n",
        "                MLPを通した後のユニット数.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(h_dim + z_dim * n_classes, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_mean = nn.Linear(hidden_dim, action_dim)\n",
        "        self.fc_std = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, h: torch.Tensor, z: torch.Tensor, eval: bool):\n",
        "        \"\"\"\n",
        "        最適行動を出力する.\n",
        "        a_t = f(h_t, z_t)\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                決定的状態h.\n",
        "            z : torch.Tensor (batch size, z_dim * n_classes)\n",
        "                確率的状態z.\n",
        "            eval : bool\n",
        "                評価モードかどうか.\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "            actions : torch.Tensor (batch size, action_dim)\n",
        "                最適行動.\n",
        "            action_log_probs : torch.Tensor (batch size, 1)\n",
        "                最適行動の対数尤度.\n",
        "            action_entropy : torch.Tensor (batch size, 1)\n",
        "                最適行動のエントロピー.\n",
        "        \"\"\"\n",
        "        x = F.elu(self.fc1(torch.cat([h, z], dim=1)))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        mean = self.fc_mean(x)\n",
        "        std = F.softplus(self.fc_std(x))\n",
        "\n",
        "        if eval:\n",
        "            actions = torch.tanh(mean) # action spaceを(-1, 1)にしてる. 環境によっては変更必要かも.\n",
        "            return actions, None, None\n",
        "\n",
        "        # Dreamer V2の連続空間でのActorがどうなっているかいまいち分からなかったので、とりあえず以下のように実装しました。\n",
        "        # まずactionを正規分布からサンプルした後、tanh関数に通して(-1, 1)にします。\n",
        "        # 対数尤度を求めるときに、log p(actions) = log Normal(unscaled_actions) * |det(∂unscaled_actions / ∂actions)|(https://arxiv.org/pdf/1801.01290 Appendix C)となります\n",
        "        # tanhの微分は1-tanh^2で、正規分布の分散共分散行列は対角行列なので、ヤコビアンはdiag(1 - tanh^2)となります。\n",
        "        # 間違ってるかもしれません...\n",
        "        action_dist = td.Independent(Normal(mean, std), 1)\n",
        "        unscaled_actions = action_dist.rsample()\n",
        "        actions = torch.tanh(unscaled_actions)\n",
        "\n",
        "        action_log_probs = action_dist.log_prob(unscaled_actions) - torch.log(1 - actions.pow(2) + 1e-7).sum(dim=1, keepdim=True)\n",
        "        action_entropy = action_dist.entropy()\n",
        "        return actions, action_log_probs, action_entropy"
      ],
      "metadata": {
        "id": "m6cwAbsdPWlD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}