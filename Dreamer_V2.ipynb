{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNea+oRYCzS4Y+ryYJJtXJj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seki-shu/Group15_Multimodal/blob/Dreamer-V2/Dreamer_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 準備"
      ],
      "metadata": {
        "id": "TfdWO2_f_ZwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## libraryのimport"
      ],
      "metadata": {
        "id": "0GIGUoGO-vBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.distributions as td\n",
        "from torch.distributions import Normal, Categorical, OneHotCategorical, OneHotCategoricalStraightThrough\n",
        "from torch.distributions import kl_divergence"
      ],
      "metadata": {
        "id": "6IyU5N79-2YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## deviceの確認"
      ],
      "metadata": {
        "id": "eKy-1uif_TRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.deviceを定義．この変数は後々モデルやデータをGPUに転送する時にも使います\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "ogLmXvsB_gPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデルの実装\n"
      ],
      "metadata": {
        "id": "OpdMlxUpvtI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RSSM"
      ],
      "metadata": {
        "id": "Ucy9NSR8vxgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RSSM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        mlp_hidden_dim: int,\n",
        "        h_dim: int,\n",
        "        z_dim: int,\n",
        "        a_dim: int,\n",
        "        n_classes: int,\n",
        "        embedding_dim: int\n",
        "    )\n",
        "    super().__init__()\n",
        "\n",
        "    self.h_dim = h_dim # 決定的状態. stoch\n",
        "    self.z_dim = z_dim # 確率的状態(カテゴリカル変数). deter\n",
        "    self.a_dim = a_dim # 行動\n",
        "    self.n_classes = n_classes # zのカテゴリ数\n",
        "\n",
        "    # Recurrent model\n",
        "    # h_t = f(h_t-1, z_t-1, a_t-1)\n",
        "    self.z_a_hidden = nn.Linear(z_dim * n_classes + a_dim, mlp_hidden_dim)\n",
        "    self.rnn = nn.GRUCell(mlp_hidden_dim, h_dim)\n",
        "\n",
        "    # Prior prediction\n",
        "    # z_t+1_hat = f(h_t+1)\n",
        "    self.prior_hidden = nn.Linear(h_dim, mlp_hidden_dim)\n",
        "    self.prior_logits = nn.Linear(mlp_hidden_dim, z_dim * n_classes)\n",
        "\n",
        "    # Posterior\n",
        "    # z_t+1 = f(h_t+1, o_t+1)\n",
        "    self.posterior_hidden = nn.Linear(h_dim + embedding_dim, mlp_hidden_dim) # competition_baselineのほうではembedding_dimがなぜかハードコーディングされてた\n",
        "    self.posterior_logits = nn.Linear(mlp_hidden_dim, z_dim * n_classes)\n",
        "\n",
        "    def recurrent(\n",
        "        self,\n",
        "        h_prev: torch.Tensor,\n",
        "        z_prev: torch.Tensor,\n",
        "        a_prev: torch.Tensor,\n",
        "        rnn_hidden: torch.Tensor\n",
        "    ):\n",
        "        \"\"\"\n",
        "        h_t = f(h_t-1, z_t-1, a_t-1)\n",
        "        \"\"\"\n",
        "        mlp_hidden = F.elu(self.z_a_hidden(torch.cat([z_prev, a_prev], dim=1)))\n",
        "        h = self.rnn(mlp_hidden, rnn_hidden)\n",
        "        return h\n",
        "\n",
        "    def get_prior(\n",
        "        self,\n",
        "        h: torch.Tensor,\n",
        "        detach = False\n",
        "    ):\n",
        "        \"\"\"\n",
        "        z_t+1_hat ~ p(h_t+1)\n",
        "        \"\"\"\n",
        "        mlp_hidden = F.elu(self.prior_hidden(h))\n",
        "        logits = self.prior_logits(mlp_hidden) # (B, z_dim * n_classes,)\n",
        "        logits = logits.reshape(logits.shape[0], self.z_dim, self.n_classes) # (B, z_dim, n_classes)\n",
        "\n",
        "        prior = td.Independent(OneHotCategoricalStraightThrough(logits=logits), 1)\n",
        "        if detach:\n",
        "            detached_prior = td.Independent(OneHotCategoricalStraightThrough(logits=logits.detach()), 1)\n",
        "            return prior, detached_prior\n",
        "        return prior\n",
        "\n",
        "    def get_posterior(\n",
        "        self,\n",
        "        h: torch.Tensor,\n",
        "        embedded_obs: torch.Tensor,\n",
        "        detach = False\n",
        "    ):\n",
        "        \"\"\"\n",
        "        z_t+1 ~ p(h_t+1, o_t+1)\n",
        "        \"\"\"\n",
        "        mlp_hidden = F.elu(self.posterior_hidden(torch.cat([h, embedded_obs], dim=1)))\n",
        "        logits = self.posterior_logits(mlp_hidden) # (B, z_dim * n_classes)\n",
        "        logits = logits.reshape(logits.shape[0], self.z_dim, self.n_classes) # (B, z_dim, n_classes)\n",
        "\n",
        "        posterior = td.Independent(OneHotCategoricalStraightThrough(logits=logits), 1)\n",
        "        if detach:\n",
        "            detached_posterior = td.Independent(OneHotCategoricalStraightThrough(logits=logits.detach()), 1)\n",
        "            return posterior, detached_posterior\n",
        "        return posterior"
      ],
      "metadata": {
        "id": "zEnpQhwuv2ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "WMago0IsS1Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    (3, 64, 64) -> (1024, ) にエンコード\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2)\n",
        "\n",
        "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        順伝播を行うメソッド．観測画像をベクトルに埋め込む．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        obs : torch.Tensor (batch size, 3, 64, 64)\n",
        "            環境から得られた観測画像．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        embed : torch.Tensor (batch size, 1024)\n",
        "            観測を1024次元のベクトルに埋め込んだもの．\n",
        "        \"\"\"\n",
        "        embed = F.elu(self.conv1(obs))\n",
        "        embed = F.elu(self.conv2(embed))\n",
        "        embed = F.elu(self.conv3(embed))\n",
        "        embed = F.elu(self.conv4(embed)).reshape(embed.shape[0], -1)\n",
        "        return embed"
      ],
      "metadata": {
        "id": "B5f9vR5_6YrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "3CrHwaS6S3fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    内部状態表現h, zから画像(3, 64, 64)を再構成する.\n",
        "    o_t+1 = f(h_t+1, z_t+1)\n",
        "    \"\"\"\n",
        "    def __init__(self, h_dim, z_dim):\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        h_dim : int\n",
        "            決定的状態hの次元数．\n",
        "        z_dim : int\n",
        "            確率的状態hの次元数．\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(h_dim + z_dim, 1024)\n",
        "        self.deconv1 = nn.ConvTranspose2d(1024, 128, kernel_size=5, stride=2)\n",
        "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2)\n",
        "        self.deconv3 = nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2)\n",
        "        self.deconv4 = nn.ConvTranspose2d(32, 3, kernel_size=6, stride=2)\n",
        "\n",
        "    def forward(self, h: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        順伝播を行うメソッド．内部状態h, zから画像を再構成する．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        h : torch.Tensor (batch size, h_dim)\n",
        "            決定的状態h\n",
        "        z : torch.Tensor (batch size, z_dim)\n",
        "            確率的状態z\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs_dist : torch.Tensor (batch size, 3, 64, 64)\n",
        "            再構成された画像．\n",
        "        \"\"\"\n",
        "        x = self.fc(torch.cat([h, z], dim=1))\n",
        "        x = x.reshape(x.shape[0], 1024, 1, 1)\n",
        "        x = F.elu(self.deconv1(x))\n",
        "        x = F.elu(self.deconv2(x))\n",
        "        x = F.elu(self.deconv3(x))\n",
        "        mean = self.deconv4(x)\n",
        "        obs_dist = td.Independent(Normal(mean, 1), 3)\n",
        "        return obs_dist\n",
        ""
      ],
      "metadata": {
        "id": "3wS4h5LRS5ni"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}