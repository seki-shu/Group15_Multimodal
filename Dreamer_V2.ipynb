{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyLWAf9DRlWzd2e39kSwJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seki-shu/Group15_Multimodal/blob/Dreamer-V2/Dreamer_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 準備"
      ],
      "metadata": {
        "id": "TfdWO2_f_ZwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "0GIGUoGO-vBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.distributions as td\n",
        "from torch.distributions import Normal, Categorical, OneHotCategorical, OneHotCategoricalStraightThrough, Bernoulli\n",
        "from torch.distributions import kl_divergence\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "6IyU5N79-2YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check device"
      ],
      "metadata": {
        "id": "eKy-1uif_TRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.deviceを定義．この変数は後々モデルやデータをGPUに転送する時にも使います\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "ogLmXvsB_gPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TrainedModels"
      ],
      "metadata": {
        "id": "-CxOnj3kzOe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainedModels:\n",
        "    def __init__(self, *models):\n",
        "        \"\"\"\n",
        "        コンストラクタ.\n",
        "        使用例: trained_models = TrainedModels(encoder, rssm, critic, actor)\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            models : nn.Module\n",
        "                保存するモデル. 複数選択可.\n",
        "        \"\"\"\n",
        "        assert np.all([nn.Module in model.__class__.__bases__ for model in models]), \"models must be nn.Module\"\n",
        "        self.models = models\n",
        "\n",
        "    def save(self, dir: str):\n",
        "        \"\"\"\n",
        "        モデルを保存するメソッド.\n",
        "        コンストラクタで渡したモデルをすべて保存する.\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            dir : str\n",
        "                保存先ディレクトリ.\n",
        "        \"\"\"\n",
        "        for model in self.models:\n",
        "            torch.save(\n",
        "                model.state_dict(),\n",
        "                os.path.join(dir, f\"{model.__class__.__name__}.pt\")\n",
        "            )\n",
        "\n",
        "    def load(self, dir: str, device: str):\n",
        "        \"\"\"\n",
        "        モデルを読み込むメソッド.\n",
        "        ※モデルの名前とファイルの名前は同じにする.\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            dir : str\n",
        "                読み込むディレクトリ.\n",
        "            device : str\n",
        "                読み込むデバイス. 'cpu', 'cuda'\n",
        "        \"\"\"\n",
        "        for model in self.models:\n",
        "            model.load_state_dict(\n",
        "                torch.load(\n",
        "                    os.path.join(dir, f\"{model.__class__.__name__}.pt\"),\n",
        "                    map_location=device\n",
        "                )\n",
        "            )"
      ],
      "metadata": {
        "id": "H8KvY313zS7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## set_seed"
      ],
      "metadata": {
        "id": "54_T5pFN-uTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int):\n",
        "    \"\"\"\n",
        "    Pytorchとnumpyのseed値を固定する.\n",
        "\n",
        "    Params:\n",
        "    -------\n",
        "        seed : int\n",
        "          シード値.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "GhE5VP-Z-z4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデルの実装\n"
      ],
      "metadata": {
        "id": "OpdMlxUpvtI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RSSM"
      ],
      "metadata": {
        "id": "Ucy9NSR8vxgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RSSM(nn.Module):\n",
        "    \"\"\"\n",
        "    RSSMのクラス.\n",
        "\n",
        "    Methods:\n",
        "    --------\n",
        "        recurrent: 決定的状態hをrnnで得る.\n",
        "        get_prior: 確率的状態zの事前分布を得る.\n",
        "        get_posterior: 確率的状態zの事後分布を得る.\n",
        "    \"\"\"\n",
        "    def __init__(self, mlp_hidden_dim: int, h_dim: int, z_dim: int, a_dim: int, n_classes: int, embedding_dim: int):\n",
        "        \"\"\"\n",
        "        コンストラクタ.\n",
        "\n",
        "        Params:\n",
        "        --------\n",
        "            mlp_hidden_dim : int\n",
        "               mlpに通した後の次元数.\n",
        "            h_dim : int\n",
        "               決定的状態hの次元数.\n",
        "            z_dim : int\n",
        "               確率的状態zの次元数.\n",
        "            a_dim : int\n",
        "               行動の次元数.\n",
        "            n_classes : int\n",
        "               確率的状態zのカテゴリ数.\n",
        "            embedding_dim : int\n",
        "               観測画像の埋め込み次元数.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.h_dim = h_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.a_dim = a_dim\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # Recurrent model\n",
        "        # h_t = f(h_t-1, z_t-1, a_t-1)\n",
        "        self.z_a_hidden = nn.Linear(z_dim * n_classes + a_dim, mlp_hidden_dim)\n",
        "        self.rnn = nn.GRUCell(mlp_hidden_dim, h_dim)\n",
        "\n",
        "        # Prior prediction\n",
        "        # z_t+1_hat = f(h_t+1)\n",
        "        self.prior_hidden = nn.Linear(h_dim, mlp_hidden_dim)\n",
        "        self.prior_logits = nn.Linear(mlp_hidden_dim, z_dim * n_classes)\n",
        "\n",
        "        # Posterior\n",
        "        # z_t+1 = f(h_t+1, o_t+1)\n",
        "        self.posterior_hidden = nn.Linear(h_dim + embedding_dim, mlp_hidden_dim)\n",
        "        self.posterior_logits = nn.Linear(mlp_hidden_dim, z_dim * n_classes)\n",
        "\n",
        "    def recurrent(self, h_prev: torch.Tensor, z_prev: torch.Tensor, a_prev: torch.Tensor, rnn_hidden: torch.Tensor):\n",
        "        \"\"\"\n",
        "        決定的状態の状態遷移を求めるメソッド. RNNとしてGRUを使用する.\n",
        "        h_t+1 = f(h_t, z_t, a_t)\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h_prev : torch.Tensor (batch size, h_dim)\n",
        "                現在時刻の決定的状態h_t\n",
        "            z_prev : torch.Tensor (batch size, z_dim)\n",
        "                現在時刻の確率的状態z_t\n",
        "            a_prev : torch.Tensor (batch size, a_dim)\n",
        "                現在時刻のアクションa_t\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                次時刻の決定的状態h_t+1\n",
        "        \"\"\"\n",
        "        mlp_hidden = F.elu(self.z_a_hidden(torch.cat([z_prev, a_prev], dim=1)))\n",
        "        h = self.rnn(mlp_hidden, rnn_hidden)\n",
        "        return h\n",
        "\n",
        "    def get_prior(self,h: torch.Tensor, detach = False):\n",
        "        \"\"\"\n",
        "        確率的状態zの事前分布を求めるメソッド.\n",
        "        z_t+1_hat ~ p(h_t+1)\n",
        "\n",
        "        Params:\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                次時刻の決定的状態h_t+1.\n",
        "            detach : bool\n",
        "                Trueの場合、detachする.\n",
        "\n",
        "        ---------\n",
        "        Returns:\n",
        "            prior : torch.distributions.Distribution\n",
        "                事前分布を求めるためのカテゴリカル分布.\n",
        "            detached_prior : torch.distributions.Independent\n",
        "                detachされた事前分布を求めるためのカテゴリカル分布.\n",
        "        \"\"\"\n",
        "        mlp_hidden = F.elu(self.prior_hidden(h))\n",
        "        logits = self.prior_logits(mlp_hidden) # (B, z_dim * n_classes,)\n",
        "        logits = logits.reshape(logits.shape[0], self.z_dim, self.n_classes) # (B, z_dim, n_classes)\n",
        "\n",
        "        prior = td.Independent(OneHotCategoricalStraightThrough(logits=logits), 1)\n",
        "        if detach:\n",
        "            detached_prior = td.Independent(OneHotCategoricalStraightThrough(logits=logits.detach()), 1)\n",
        "            return prior, detached_prior\n",
        "        return prior\n",
        "\n",
        "    def get_posterior(self, h: torch.Tensor, embedded_obs: torch.Tensor, detach = False):\n",
        "        \"\"\"\n",
        "        確率的状態zの事後分布を求めるメソッド.\n",
        "        z_t+1 ~ p(h_t+1, o_t+1)\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                次時刻の決定的状態h_t+1.\n",
        "            embedded_obs : torch.Tensor (batch size, embedding_dim)\n",
        "                次時刻の画像の埋め込み\n",
        "            detach : bool\n",
        "                Trueの場合、detachする.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "            posterior : torch.distributions.Distribution\n",
        "                事後分布を求めるためのカテゴリカル分布.\n",
        "            detached_posterior : torch.distributions.Independent\n",
        "                detachされた事後分布を求めるためのカテゴリカル分布.\n",
        "        \"\"\"\n",
        "        mlp_hidden = F.elu(self.posterior_hidden(torch.cat([h, embedded_obs], dim=1)))\n",
        "        logits = self.posterior_logits(mlp_hidden) # (B, z_dim * n_classes)\n",
        "        logits = logits.reshape(logits.shape[0], self.z_dim, self.n_classes) # (B, z_dim, n_classes)\n",
        "\n",
        "        posterior = td.Independent(OneHotCategoricalStraightThrough(logits=logits), 1)\n",
        "        if detach:\n",
        "            detached_posterior = td.Independent(OneHotCategoricalStraightThrough(logits=logits.detach()), 1)\n",
        "            return posterior, detached_posterior\n",
        "        return posterior"
      ],
      "metadata": {
        "id": "zEnpQhwuv2ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "WMago0IsS1Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    画像(3, 64, 64)をエンコードする.\n",
        "\n",
        "    Methods:\n",
        "    -------\n",
        "        forward: 観測画像を埋め込む.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2)\n",
        "\n",
        "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        順伝播を行うメソッド．観測画像をベクトルに埋め込む．\n",
        "        (3, 64, 64) -> (1024, ) にエンコード\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            obs : torch.Tensor (batch size, 3, 64, 64)\n",
        "                環境から得られた観測画像．\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "            embed : torch.Tensor (batch size, 1024)\n",
        "                観測を1024次元のベクトルに埋め込んだもの．\n",
        "        \"\"\"\n",
        "        embed = F.elu(self.conv1(obs))\n",
        "        embed = F.elu(self.conv2(embed))\n",
        "        embed = F.elu(self.conv3(embed))\n",
        "        embed = F.elu(self.conv4(embed)).reshape(embed.shape[0], -1)\n",
        "        return embed"
      ],
      "metadata": {
        "id": "B5f9vR5_6YrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "3CrHwaS6S3fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    内部状態表現h, zから画像(3, 64, 64)を再構成する.\n",
        "    ただし画像は平均を計算して、その平均で分散１の正規分布から得る.\n",
        "\n",
        "    Methods:\n",
        "        forward: 画像の再構成を行う.\n",
        "    \"\"\"\n",
        "    def __init__(self, h_dim: int, z_dim: int, n_classes: int):\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Params:\n",
        "        --------\n",
        "            h_dim : int\n",
        "                決定的状態hの次元数．\n",
        "            z_dim : int\n",
        "                確率的状態zの次元数．\n",
        "            n_classes : int\n",
        "                確率的状態zのカテゴリ数．\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(h_dim + z_dim * n_classes, 1024)\n",
        "        self.deconv1 = nn.ConvTranspose2d(1024, 128, kernel_size=5, stride=2)\n",
        "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2)\n",
        "        self.deconv3 = nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2)\n",
        "        self.deconv4 = nn.ConvTranspose2d(32, 3, kernel_size=6, stride=2)\n",
        "\n",
        "    def forward(self, h: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        順伝播を行うメソッド．内部状態h, zから画像を再構成する．\n",
        "        mean = f(h_t, z_t)\n",
        "        o_t = N(mean, 1)\n",
        "\n",
        "        Params:\n",
        "        --------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                決定的状態h\n",
        "            z : torch.Tensor (batch size, z_dim * n_classes)\n",
        "                確率的状態z\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "            obs_dist : torch.distributions.Independent\n",
        "                再構成された画像を得るための多変量正規分布．\n",
        "        \"\"\"\n",
        "        x = self.fc(torch.cat([h, z], dim=1))\n",
        "        x = x.reshape(x.shape[0], 1024, 1, 1)\n",
        "        x = F.elu(self.deconv1(x))\n",
        "        x = F.elu(self.deconv2(x))\n",
        "        x = F.elu(self.deconv3(x))\n",
        "        mean = self.deconv4(x)\n",
        "        obs_dist = td.Independent(Normal(mean, 1), 3)\n",
        "        return obs_dist\n"
      ],
      "metadata": {
        "id": "3wS4h5LRS5ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reward Model"
      ],
      "metadata": {
        "id": "NqLaH-bVcdAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RewardModel(nn.Module):\n",
        "    \"\"\"\n",
        "    報酬予測モデル.\n",
        "    ただし報酬は平均を計算して、その平均で分散が1の正規分布から得る.\n",
        "\n",
        "    Methods:\n",
        "    -------\n",
        "        forward: 報酬予測を行う.\n",
        "    \"\"\"\n",
        "    def __init__(self, h_dim: int, z_dim: int, n_classes: int, hidden_dim: int):\n",
        "        \"\"\"\n",
        "        コンストラクタ.\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h_dim : int\n",
        "                決定的状態hの次元数.\n",
        "            z_dim : int\n",
        "                確率的状態zの次元数.\n",
        "            n_classes : int\n",
        "                確率的状態zのカテゴリ数.\n",
        "            hidden_dim : int\n",
        "                MLPを通した後のユニット数.\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(h_dim + z_dim * n_classes, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, h: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        報酬予測を行うメソッド.\n",
        "        mean = f(h_t, z_t)\n",
        "        r_t = N(mean, 1)\n",
        "\n",
        "        Params:\n",
        "        ----------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                決定的状態h\n",
        "            z : torch.Tensor (batch size, z_dim * n_classes)\n",
        "                確率的状態z\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "            reward_dist : torch.distributions.Independent\n",
        "                報酬予測をするための多変量正規分布.\n",
        "        \"\"\"\n",
        "        x = F.elu(self.fc1(torch.cat([h, z], dim=1)))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        mean = self.fc4(x)\n",
        "        reward_dist = td.Independent(Normal(mean, 1), 1)\n",
        "        return reward_dist"
      ],
      "metadata": {
        "id": "kT1UTPlFcfuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discount Model\n"
      ],
      "metadata": {
        "id": "ulP85WUBKp4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiscountModel(nn.Module):\n",
        "    \"\"\"\n",
        "    現在のエピソードが終端かどうかを求めるモデル.\n",
        "\n",
        "    Methods:\n",
        "    --------\n",
        "        forward: 終端かどうか予測を行う.\n",
        "    \"\"\"\n",
        "    def __init__(self, h_dim: int, z_dim: int, n_classes: int, hidden_dim: int):\n",
        "        \"\"\"\n",
        "        コンストラクタ.\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h_dim : int\n",
        "                決定的状態hの次元数.\n",
        "            z_dim : int\n",
        "                確率的状態zの次元数.\n",
        "            n_classes : int\n",
        "                確率的状態zのカテゴリ数.\n",
        "            hidden_dim : int\n",
        "                MLPを通した後のユニット数.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(h_dim + z_dim * n_classes, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, h: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        現在のエピソードが終端かどうか求める.\n",
        "        p = f(h_t, z_t)\n",
        "        gamma_t = Bernoulli(p)\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                決定的状態h\n",
        "            z : torch.Tensor (batch size, z_dim * n_classes)\n",
        "                確率的状態z\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "            discount_dist : torch.distributions.Independent\n",
        "                終端かどうか予測を行うベルヌーイ分布\n",
        "        \"\"\"\n",
        "        x = F.elu(self.fc1(torch.cat([h, z], dim=1)))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        p_logits = self.fc4(x)\n",
        "        discount_dist = td.Independent(Bernoulli(logits=p_logits), 1)\n",
        "        return discount_dist"
      ],
      "metadata": {
        "id": "50mWXQbCKt6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actor"
      ],
      "metadata": {
        "id": "sc3et5bZPUEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Actor(nn.Module):\n",
        "    \"\"\"\n",
        "    最適行動を出力するモデル.\n",
        "    今回はAtariではないので連続な行動を出力する.\n",
        "\n",
        "    Methods:\n",
        "    -------\n",
        "        forward: 最適行動を出力する.\n",
        "    \"\"\"\n",
        "    def __init__(self, action_dim: int, h_dim: int, z_dim: int, n_classes: int, hidden_dim: int):\n",
        "        \"\"\"\n",
        "        コンストラクタ.\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            action_dim : int\n",
        "                行動の次元数.\n",
        "            h_dim : int\n",
        "                決定的状態hの次元数.\n",
        "            z_dim : int\n",
        "                確率的状態zの次元数.\n",
        "            n_classes : int\n",
        "                確率的状態zのカテゴリ数.\n",
        "            hidden_dim : int\n",
        "                MLPを通した後のユニット数.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(h_dim + z_dim * n_classes, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_mean = nn.Linear(hidden_dim, action_dim)\n",
        "        self.fc_std = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, h: torch.Tensor, z: torch.Tensor, eval: bool):\n",
        "        \"\"\"\n",
        "        最適行動を出力する.\n",
        "        a_t = f(h_t, z_t)\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                決定的状態h.\n",
        "            z : torch.Tensor (batch size, z_dim * n_classes)\n",
        "                確率的状態z.\n",
        "            eval : bool\n",
        "                評価モードかどうか.\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "            actions : torch.Tensor (batch size, action_dim)\n",
        "                最適行動.\n",
        "            action_log_probs : torch.Tensor (batch size, 1)\n",
        "                最適行動の対数尤度.\n",
        "            action_entropy : torch.Tensor (batch size, 1)\n",
        "                最適行動のエントロピー.\n",
        "        \"\"\"\n",
        "        x = F.elu(self.fc1(torch.cat([h, z], dim=1)))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        mean = self.fc_mean(x)\n",
        "        std = F.softplus(self.fc_std(x))\n",
        "\n",
        "        if eval:\n",
        "            actions = torch.tanh(mean) # action spaceを(-1, 1)にしてる. 環境によっては変更必要かも.\n",
        "            return actions, None, None\n",
        "\n",
        "        # Dreamer V2の連続空間でのActorがどうなっているかいまいち分からなかったので、とりあえず以下のように実装しました。\n",
        "        # まずactionを正規分布からサンプルした後、tanh関数に通して(-1, 1)にします。\n",
        "        # 対数尤度を求めるときに、log p(actions) = log Normal(unscaled_actions) * |det(∂unscaled_actions / ∂actions)|(https://arxiv.org/pdf/1801.01290 Appendix C)となります\n",
        "        # tanhの微分は1-tanh^2で、正規分布の分散共分散行列は対角行列なので、ヤコビアンはdiag(1 - tanh^2)となります。\n",
        "        # 間違ってるかもしれません...\n",
        "        action_dist = td.Independent(Normal(mean, std), 1)\n",
        "        unscaled_actions = action_dist.rsample()\n",
        "        actions = torch.tanh(unscaled_actions)\n",
        "\n",
        "        action_log_probs = action_dist.log_prob(unscaled_actions) - torch.log(1 - actions.pow(2) + 1e-7).sum(dim=1, keepdim=True)\n",
        "        action_entropy = action_dist.entropy()\n",
        "        return actions, action_log_probs, action_entropy"
      ],
      "metadata": {
        "id": "m6cwAbsdPWlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Critic"
      ],
      "metadata": {
        "id": "GarQGZjT0nNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Critic(nn.Module):\n",
        "    \"\"\"\n",
        "    状態価値を出力するモデル.\n",
        "\n",
        "    Methods:\n",
        "    --------\n",
        "        forward: 状態価値を出力する.\n",
        "    \"\"\"\n",
        "    def __init__(self, h_dim: int, z_dim: int, n_classes: int, hidden_dim: int):\n",
        "        \"\"\"\n",
        "        コンストラクタ.\n",
        "\n",
        "        params:\n",
        "        -------\n",
        "            h_dim : int\n",
        "                決定的状態hの次元数.\n",
        "            z_dim : int\n",
        "                確率的状態zの次元数.\n",
        "            n_classes : int\n",
        "                確率的状態zのカテゴリ数.\n",
        "            hidden_dim : int\n",
        "                MLPを通した後のユニット数.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(h_dim + z_dim * n_classes, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.out = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, h: torch.Tensor, z: torch.Tensor):\n",
        "        \"\"\"\n",
        "        状態価値を出力する.\n",
        "        v_t = f(h_t, z_t)\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            h : torch.Tensor (batch size, h_dim)\n",
        "                決定的状態h.\n",
        "            z : torch.Tensor (batch size, z_dim * n_classes)\n",
        "                確率的状態z.\n",
        "\n",
        "        Return:\n",
        "        -------\n",
        "            values : torch.Tensor (batch size, 1)\n",
        "                状態価値.\n",
        "        \"\"\"\n",
        "        x = F.elu(self.fc1(torch.cat([h, z], dim=1)))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        values = self.out(x)\n",
        "        return values"
      ],
      "metadata": {
        "id": "Ywfm04w10piP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# その他機能"
      ],
      "metadata": {
        "id": "mPznwrXrB-wD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replay Buffer\n"
      ],
      "metadata": {
        "id": "parOAYbvCCP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"\n",
        "    リプレイバッファ.\n",
        "    \"\"\"\n",
        "    def __init__(self, capacity: int, obs_shape: tuple[int], action_dim: int):\n",
        "        \"\"\"\n",
        "        コンストラクタ.\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            capacity : int\n",
        "                バッファの最大容量.\n",
        "            obs_shape : tuple[int]\n",
        "                観測の形状.\n",
        "            action_dim : int\n",
        "                行動の次元数.\n",
        "        \"\"\"\n",
        "        self.capacity = capacity\n",
        "        self.obs_shape = obs_shape\n",
        "        self.action_dim = action_dim\n",
        "\n",
        "        self.observations = np.zeros((capacity, *obs_shape), dtype=np.float32)\n",
        "        self.actions = np.zeros((capacity, action_dim), dtype=np.float32)\n",
        "        self.rewards = np.zeros((capacity, 1), dtype=np.float32)\n",
        "        self.dones = np.zeros((capacity, 1), dtype=bool)\n",
        "        self.index = 0\n",
        "        self.is_filled = False\n",
        "\n",
        "    def add(self, observation: np.ndarray, action: np.ndarray, reward: float, done: bool):\n",
        "        \"\"\"\n",
        "        バッファに追加する.\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            observation : np.ndarray (obs_shape)\n",
        "                観測.\n",
        "            action : np.ndarray (action_dim)\n",
        "                行動.\n",
        "            reward : float\n",
        "                報酬.\n",
        "            done : bool\n",
        "                エピソードの終了.\n",
        "        \"\"\"\n",
        "        self.observations[self.index] = observation\n",
        "        self.actions[self.index] = action\n",
        "        self.rewards[self.index] = reward\n",
        "        self.dones[self.index] = done\n",
        "\n",
        "        if self.index == self.capacity - 1:\n",
        "            self.is_filled = True\n",
        "        self.index = (self.index + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size: int, chunk_length: int) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        バッファからサンプリングする.\n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "            batch_size : int\n",
        "                サンプリングするデータの数.\n",
        "\n",
        "            chunk_length : int\n",
        "                chunkの長さ\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "            sampled_observations : np.ndarray\n",
        "                サンプリングされた観測.\n",
        "            sampled_actions : np.ndarray\n",
        "                サンプリングされた行動.\n",
        "            sampled_rewards : np.ndarray\n",
        "                サンプリングされた報酬.\n",
        "            sampled_dones : np.ndarray\n",
        "                サンプリングされたエピソードの終了判定.\n",
        "        \"\"\"\n",
        "        episode_borders = np.where(self.dones)[0] # episodeが終了するindex\n",
        "        sampled_indices = []\n",
        "        for _ in range(batch_size):\n",
        "            crossed_border = True # borderを跨いだかどうか\n",
        "            while crossed_border:\n",
        "                initial_idx = np.random.randint(self.capacity - chunk_length + 1)\n",
        "                final_idx = initial_idx + chunk_length - 1\n",
        "                crossed_border = np.logical_and(initial_idx <= episode_borders,\n",
        "                                                episode_borders < final_idx).any()\n",
        "            sampled_indices += list(range(initial_idx, final_idx + 1)) # 最終的に(batch_size * chunk_length)\n",
        "\n",
        "        sampled_observations = self.observations[sampled_indices].reshape(\n",
        "            batch_size, chunk_length, *self.obs_shape)\n",
        "        sampled_actions = self.actions[sampled_indices].reshape(\n",
        "            batch_size, chunk_length, self.action_dim)\n",
        "        sampled_rewards = self.rewards[sampled_indices].reshape(\n",
        "            batch_size, chunk_length, 1)\n",
        "        sampled_dones = self.dones[sampled_indices].reshape(\n",
        "            batch_size, chunk_length, 1)\n",
        "        return sampled_observations, sampled_actions, sampled_rewards, sampled_dones\n",
        "\n",
        "    def save(self, dir: str):\n",
        "        np.save(f\"{dir}/observations.npy\", self.observations)\n",
        "        np.save(f\"{dir}/actions.npy\", self.actions)\n",
        "        np.save(f\"{dir}/rewards.npy\", self.rewards)\n",
        "        np.save(f\"{dir}/dones.npy\", self.dones)\n",
        "\n",
        "    def load(self, dir: str):\n",
        "        self.observations = np.load(f\"{dir}/observations.npy\")\n",
        "        self.actions = np.load(f\"{dir}/actions.npy\")\n",
        "        self.rewards = np.load(f\"{dir}/rewards.npy\")\n",
        "        self.dones = np.load(f\"{dir}/dones.npy\")\n"
      ],
      "metadata": {
        "id": "7RSO7DksDr36"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}